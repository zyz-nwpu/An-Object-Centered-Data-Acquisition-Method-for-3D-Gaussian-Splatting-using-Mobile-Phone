<!doctype html>
<html lang="en" style="--lh:2.0;">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Object-Centered Data Acquisition for 3DGS ‚Äî Project Page</title>
  <meta name="description" content="Project page for 'An Object-Centered Data Acquisition Method for 3D Gaussian Splatting using Mobile Phone'. Includes supplementary results, demos, and ablation studies." />
  <link rel="canonical" href="https://zyz-nwpu.github.io/An-Object-Centered-Data-Acquisition-Method-for-3D-Gaussian-Splatting-using-Mobile-Phone/" />
  <style>
    :root{
      --fg:#111; --muted:#555; --line:#eaeaea; --bg:#f9f9f9; --card:#fff;
      --radius:12px; --pad:20px;
      --content-w: 1100px;
      --vid-h: 500px;
      --accent: #0b57d0;
    }
    *{box-sizing:border-box}
    body{
      margin:0;
      font-family:-apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      color:var(--fg); background:var(--bg);
      line-height:1.6;
      font-size:16px;
    }
    a{color:var(--accent);text-decoration:none; transition: opacity 0.2s;}
    a:hover{opacity: 0.8; text-decoration:underline}
    
    /* Navigation */
    nav{position:sticky;top:0;z-index:100;background:rgba(255,255,255,0.95);border-bottom:1px solid var(--line); backdrop-filter: blur(10px);}
    .navwrap{
      max-width:var(--content-w); margin:0 auto; padding:12px var(--pad);
      display:flex; align-items:center; justify-content:space-between; flex-wrap:wrap; gap:10px;
    }
    .btn{
      display:inline-flex; align-items:center; padding:6px 14px;
      border:1px solid #ddd; border-radius:8px; background:#fff;
      color:#333; font-size:14px; font-weight:500;
    }
    .btn:hover{background:#f5f5f5; border-color:#ccc;}

    /* Main Layout */
    .wrap{
      max-width:var(--content-w); margin:24px auto 40px; padding:0 var(--pad);
    }
    .card{
      background:var(--card); border:1px solid var(--line); border-radius:var(--radius);
      padding:24px; box-shadow:0 2px 8px rgba(0,0,0,0.02); margin-bottom:20px;
    }
    
    /* Typography */
    h1{margin:0 0 16px; font-size:28px; line-height:1.3; font-weight:700; color:#111;}
    h2{margin:0; font-size:20px; font-weight:600;}
    p{margin:12px 0; color:#333;}
    ul{margin:10px 0 10px 20px; color:#333;}
    li{margin:6px 0;}
    
    /* Header Icons */
    .hrow{display:flex;align-items:center;gap:10px;margin-bottom:16px; padding-bottom:10px; border-bottom:1px solid #eee;}
    .hicon{font-size:24px;}
    
    /* Media & Grid */
    figure{margin:0; border:1px solid var(--line); border-radius:8px; overflow:hidden;}
    .media-block{padding:10px; background:#fafafa; text-align:center;}
    .media-block img{max-width:100%; height:auto; border-radius:4px;}
    
    .media-desc{
      margin: 16px 0 12px; padding: 12px 16px;
      background:#f4f7fc; border-left: 4px solid var(--accent);
      border-radius:4px; font-size:14px; color:#444;
    }
    
    .video-grid{
      display:grid; grid-template-columns: 1fr 1fr; gap:20px; margin-top:10px;
    }
    @media (max-width: 850px){ .video-grid{ grid-template-columns: 1fr; } }
    
    .video-cell{
      border:1px solid var(--line); border-radius:10px; padding:10px; background:#fff;
    }
    .video-title{
      font-size:14px; font-weight:600; text-align:center; margin-bottom:8px; color:#444;
    }
    .video-frame{
      background:#000; border-radius:6px; overflow:hidden;
      display:flex; align-items:center; justify-content:center;
      aspect-ratio: 9/16; /* Mobile portrait aspect ratio */
      max-height: var(--vid-h);
    }
    .video-frame video{
      width:100%; height:100%; object-fit:contain;
    }

    /* Thumbnails */
    .thumb-row{
      display:grid; grid-template-columns:repeat(4,1fr); gap:10px; margin:16px 0;
    }
    .thumb-row img{
      width:100%; aspect-ratio: 1/1; object-fit:cover;
      border-radius:8px; border:1px solid var(--line);
    }

    /* Tables */
    .table-container {
      width: 100%; overflow-x: auto; margin: 16px 0;
      border: 1px solid var(--line); border-radius: 8px;
    }
    table {
      width: 100%; border-collapse: collapse; font-size: 13px; text-align: center;
    }
    th, td { padding: 8px 6px; border-bottom: 1px solid #eee; }
    th { background-color: #f8f9fa; font-weight: 600; color: #444; }
    tr:last-child td { border-bottom: none; }
    caption {
      caption-side: top; text-align: left; padding: 10px 12px;
      font-weight: 700; font-size: 14px; color: #222; background: #fff;
      border-bottom: 1px solid #eee;
    }

    footer{margin:40px 0; color:var(--muted); font-size:13px; text-align:center;}
  </style>
</head>
<body>
  <nav>
    <div class="navwrap">
      <div style="font-weight:600; font-size:18px;">3DGS Capture</div>
      <div style="display:flex;gap:8px;">
        <a class="btn" href="https://github.com/zyz-nwpu/An-Object-Centered-Data-Acquisition-Method-for-3D-Gaussian-Splatting-using-Mobile-Phone">View Code</a>
        <a class="btn" href="https://github.com/zyz-nwpu/An-Object-Centered-Data-Acquisition-Method-for-3D-Gaussian-Splatting-using-Mobile-Phone/releases/tag/v1.1">Release v1.1</a>
      </div>
    </div>
  </nav>

  <main class="wrap">
    <!-- Abstract -->
    <section class="card">
      <h1>An Object-Centered Data Acquisition Method for 3D Gaussian Splatting using Mobile Phone</h1>
      <div class="hrow"><span class="hicon">üìù</span><h2>Abstract</h2></div>
      <p>
        High-quality 3D Gaussian Splatting (3DGS) reconstruction relies heavily on accurate poses and comprehensive viewpoint coverage. 
        We present a mobile, <strong>object-centered data acquisition framework</strong> that addresses these challenges through on-device guidance and sensor fusion. 
        Our system maps the camera's optical axis to a <strong>discretized spherical grid</strong> after a one-time calibration. 
        By providing <strong>real-time, area-weighted coverage feedback</strong> and employing a <strong>stability gate</strong> based on smoothed IMU signals, 
        we ensure that users capture uniform, blur-free images essential for high-fidelity reconstruction.
      </p>
      
      <div class="hrow" style="margin-top:24px;"><span class="hicon">üí°</span><h2>Key Contributions</h2></div>
      <ul>
        <li><strong>Spherical Mapping:</strong> Transformation of IMU-based device orientations into an object-centered spherical coordinate system.</li>
        <li><strong>Coverage Guidance:</strong> Real-time visualization of area-weighted spherical coverage to ensure angular uniformity and completeness.</li>
        <li><strong>Stability Control:</strong> A dual-mode stability gate (using linear acceleration and angular velocity) to filter out motion blur and unstable poses.</li>
      </ul>

      <div class="hrow" style="margin-top:24px;"><span class="hicon">‚öôÔ∏è</span><h2>Experimental Setup</h2></div>
      <ul>
        <li><strong>Mobile Device:</strong> Redmi K70 Pro (Data logging & Real-time guidance).</li>
        <li><strong>Workstation:</strong> NVIDIA RTX 5090D (Offline 3DGS training & reconstruction).</li>
        <li><strong>Targets:</strong> Various tabletop objects with complex geometries and textures.</li>
      </ul>
    </section>

    <!-- Method & Visuals -->
    <section class="card">
      <div class="hrow"><span class="hicon">üñºÔ∏è</span><h2>System Overview & Demonstration</h2></div>

      <!-- Method figure -->
      <figure style="max-width: 800px; margin: 0 auto 20px;">
        <div class="media-block">
          <img src="./picture1_01.png" alt="System Workflow Diagram" loading="lazy">
        </div>
        <div class="media-desc" style="margin:0; border:none; background:none; text-align:center; font-size:13px; color:#666;">
          <strong>Figure 1. System Workflow.</strong> From calibration to stability gating, spherical mapping, and real-time coverage updates.
        </div>
      </figure>

      <p><strong>Dataset Objects:</strong> The following objects were used to validate our method (miniclawmachine, bearplanter, terracotta warrior replica, coinbank).</p>
      <div class="thumb-row">
        <img src="https://github.com/zyz-nwpu/An-Object-Centered-Data-Acquisition-Method-for-3D-Gaussian-Splatting-using-Mobile-Phone/releases/download/v1/4.png" alt="Object 4">
        <img src="https://github.com/zyz-nwpu/An-Object-Centered-Data-Acquisition-Method-for-3D-Gaussian-Splatting-using-Mobile-Phone/releases/download/v1/1.png" alt="Object 1">
        <img src="https://github.com/zyz-nwpu/An-Object-Centered-Data-Acquisition-Method-for-3D-Gaussian-Splatting-using-Mobile-Phone/releases/download/v1/2.png" alt="Object 2">
        <img src="https://github.com/zyz-nwpu/An-Object-Centered-Data-Acquisition-Method-for-3D-Gaussian-Splatting-using-Mobile-Phone/releases/download/v1/3.png" alt="Object 3">
      </div>

      <!-- Video Section 1: UI Demo -->
      <div class="media-desc">
        <strong>Real-time Guidance Interface:</strong> The screen recordings below demonstrate the mobile app in action. Note the spherical grid overlay filling up as the user orbits the object, ensuring no view is missed.
      </div>
      <div class="video-grid">
        <div class="video-cell">
          <div class="video-title">Capture UI ‚Äî Bearplanter</div>
          <div class="video-frame">
            <video controls autoplay muted loop playsinline preload="metadata" src="https://github.com/zyz-nwpu/An-Object-Centered-Data-Acquisition-Method-for-3D-Gaussian-Splatting-using-Mobile-Phone/releases/download/v1/2.mp4"></video>
          </div>
        </div>
        <div class="video-cell">
          <div class="video-title">Capture UI ‚Äî Terracotta Warrior</div>
          <div class="video-frame">
            <video controls autoplay muted loop playsinline preload="metadata" src="https://github.com/zyz-nwpu/An-Object-Centered-Data-Acquisition-Method-for-3D-Gaussian-Splatting-using-Mobile-Phone/releases/download/v1/3.mp4"></video>
          </div>
        </div>
      </div>

      <!-- Video Section 2: Capture vs Recon -->
      <div class="media-desc">
        <strong>Reconstruction Results:</strong> Comparison between the capture process (left) and the final 3DGS rendering (right). 
        Full datasets and models are available for <a href="https://pan.quark.cn/s/755b80a07051" target="_blank"><strong>download here</strong></a>.
      </div>
      <div class="video-grid">
        <!-- Row 1 -->
        <div class="video-cell">
          <div class="video-title">Capture Process ‚Äî Miniclawmachine</div>
          <div class="video-frame">
            <video controls autoplay muted loop playsinline preload="metadata" src="https://github.com/zyz-nwpu/An-Object-Centered-Data-Acquisition-Method-for-3D-Gaussian-Splatting-using-Mobile-Phone/releases/download/v1/1.mp4"></video>
          </div>
        </div>
        <div class="video-cell">
          <div class="video-title">3DGS Render ‚Äî Miniclawmachine</div>
          <div class="video-frame">
            <video controls autoplay muted loop playsinline preload="metadata" src="https://github.com/zyz-nwpu/An-Object-Centered-Data-Acquisition-Method-for-3D-Gaussian-Splatting-using-Mobile-Phone/releases/download/v1/1.1.mp4"></video>
          </div>
        </div>
        <!-- Row 2 -->
        <div class="video-cell">
          <div class="video-title">Capture Process ‚Äî Coinbank</div>
          <div class="video-frame">
            <video controls autoplay muted loop playsinline preload="metadata" src="https://github.com/zyz-nwpu/An-Object-Centered-Data-Acquisition-Method-for-3D-Gaussian-Splatting-using-Mobile-Phone/releases/download/v1/4.mp4"></video>
          </div>
        </div>
        <div class="video-cell">
          <div class="video-title">3DGS Render ‚Äî Coinbank</div>
          <div class="video-frame">
            <video controls autoplay muted loop playsinline preload="metadata" src="https://github.com/zyz-nwpu/An-Object-Centered-Data-Acquisition-Method-for-3D-Gaussian-Splatting-using-Mobile-Phone/releases/download/v1/4.1.mp4"></video>
          </div>
        </div>
      </div>
    </section>

    <!-- Results: Free vs Guided -->
    <section class="card">
      <div class="hrow"><span class="hicon">üìä</span><h2>Quantitative Evaluation: Free vs. Guided Capture</h2></div>
      <p>
        We conducted a user study comparing unguided "Free Capture" against our "Guided Capture" method. 
        Table 1 highlights that while free capture often results in uneven distribution (biased towards frontal views), 
        our guided method achieves <strong>100% spherical coverage</strong> with comparable or fewer images, leading to consistently higher PSNR.
        (Raw data available <a href="https://pan.quark.cn/s/aa7c9add37e7" target="_blank"><strong>here</strong></a>).
      </p>

      <div class="table-container">
        <table>
          <caption>Table 1. Photo count, coverage distribution, and PSNR comparison (Free vs. Guided).</caption>
          <thead>
            <tr>
              <th rowspan="2">Method / ID</th>
              <th colspan="2">Front (-45¬∞‚Äì45¬∞)</th>
              <th colspan="2">Right (45¬∞‚Äì135¬∞)</th>
              <th colspan="2">Back (135¬∞‚Äì-135¬∞)</th>
              <th colspan="2">Left (-135¬∞‚Äì-45¬∞)</th>
              <th colspan="2">PSNR (dB)</th>
            </tr>
            <tr>
              <th>Img</th><th>Cov</th><th>Img</th><th>Cov</th><th>Img</th><th>Cov</th><th>Img</th><th>Cov</th><th>7k</th><th>30k</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Free (User 1)</td><td>123</td><td>73%</td><td>25</td><td>44%</td><td>51</td><td>40%</td><td>42</td><td>52%</td><td>25.92</td><td>28.77</td></tr>
            <tr><td>Free (User 2)</td><td>90</td><td>69%</td><td>50</td><td>57%</td><td>79</td><td>52%</td><td>70</td><td>73%</td><td>25.23</td><td>26.95</td></tr>
            <tr><td>Free (User 3)</td><td>109</td><td>48%</td><td>63</td><td>61%</td><td>46</td><td>57%</td><td>81</td><td>48%</td><td>26.86</td><td>28.89</td></tr>
            <tr><td>Free (User 4)</td><td>63</td><td>65%</td><td>71</td><td>51%</td><td>50</td><td>32%</td><td>74</td><td>52%</td><td>25.67</td><td>26.81</td></tr>
            <tr><td>Free (User 5)</td><td>92</td><td>61%</td><td>88</td><td>60%</td><td>93</td><td>52%</td><td>57</td><td>61%</td><td>25.61</td><td>27.02</td></tr>
            <tr style="font-weight:bold; background:#f0f0f0;">
              <td>Free (Avg)</td><td>95</td><td>63%</td><td>59</td><td>55%</td><td>64</td><td>47%</td><td>65</td><td>57%</td><td>25.86</td><td>27.69</td>
            </tr>
            <tr style="background:#eefcf1; font-weight:bold; border-top:2px solid #ddd;">
              <td>Ours (Guided)</td><td>82</td><td>100%</td><td>53</td><td>100%</td><td>63</td><td>100%</td><td>60</td><td>100%</td><td>26.78</td><td>30.28</td>
            </tr>
          </tbody>
        </table>
      </div>
    </section>

    <!-- Results: COLMAP vs Hybrid -->
    <section class="card">
      <div class="hrow"><span class="hicon">üìê</span><h2>Pose Accuracy Analysis</h2></div>
      <p>
        To evaluate the utility of our IMU-based orientation estimates, we compared standard 3DGS training (using COLMAP poses) against a hybrid approach where COLMAP rotations are replaced by our device-calibrated orientations.
        Table 2 shows that our object-centered orientations yield consistent PSNR improvements, particularly in the early training stages (7k steps).
      </p>

      <div class="table-container">
        <table>
          <caption>Table 2. PSNR improvement using IMU-aligned orientations vs. Original COLMAP poses.</caption>
          <thead>
            <tr>
              <th rowspan="2">Scene</th>
              <th rowspan="2">Trial</th>
              <th colspan="2">COLMAP (Origin)</th>
              <th colspan="2">Ours (Hybrid)</th>
              <th rowspan="2">Improvement (Avg)</th>
            </tr>
            <tr><th>7k</th><th>30k</th><th>7k</th><th>30k</th></tr>
          </thead>
          <tbody>
            <tr><td rowspan="4">miniclawmachine</td><td>1</td><td>24.95</td><td>27.57</td><td>25.12</td><td>27.63</td><td rowspan="4">7k: +0.59%<br>30k: +0.02%</td></tr>
            <tr><td>2</td><td>24.82</td><td>27.57</td><td>25.00</td><td>27.68</td></tr>
            <tr><td>3</td><td>25.03</td><td>27.74</td><td>25.12</td><td>27.59</td></tr>
            <tr><td>avg</td><td>24.93</td><td>27.63</td><td>25.08</td><td>27.64</td></tr>
            
            <tr style="border-top:2px solid #eee;"><td rowspan="4">bearplanter</td><td>1</td><td>26.70</td><td>28.68</td><td>26.81</td><td>28.66</td><td rowspan="4">7k: +0.25%<br>30k: +0.10%</td></tr>
            <tr><td>2</td><td>26.73</td><td>28.71</td><td>26.74</td><td>28.64</td></tr>
            <tr><td>3</td><td>26.72</td><td>28.64</td><td>26.80</td><td>28.81</td></tr>
            <tr><td>avg</td><td>26.72</td><td>28.67</td><td>26.78</td><td>28.70</td></tr>
            
            <tr style="border-top:2px solid #eee;"><td rowspan="4">coinbank_bear</td><td>1</td><td>26.35</td><td>28.45</td><td>26.42</td><td>28.49</td><td rowspan="4">7k: +0.40%<br>30k: +0.01%</td></tr>
            <tr><td>2</td><td>26.36</td><td>28.50</td><td>26.46</td><td>28.53</td></tr>
            <tr><td>3</td><td>26.29</td><td>28.44</td><td>26.44</td><td>28.38</td></tr>
            <tr><td>avg</td><td>26.34</td><td>28.46</td><td>26.44</td><td>28.46</td></tr>
          </tbody>
        </table>
      </div>
    </section>

    <!-- Ablation Study (New) -->
    <section class="card" style="border-left: 5px solid #0b57d0;">
      <div class="hrow"><span class="hicon">üìâ</span><h2>Supplementary Ablation Study: Impact of Coverage</h2></div>
      <p>
        <em>Note: This section provides supplementary experimental data not included in the main manuscript.</em>
      </p>
      <p>
        To quantitatively validate the relationship between view coverage and reconstruction fidelity, we conducted an ablation study where training views were progressively removed from a complete (100% coverage) dataset. 
        We maintained a fixed set of "Test" images to ensure a consistent evaluation baseline (Final PSNR).
      </p>
      <p>
        <strong>Observation:</strong> As shown in Tables 3 and 4, there is a clear, <strong>monotonic downward trend</strong> in reconstruction quality (Final PSNR) as the spherical coverage percentage decreases. 
        This degradation confirms that high-density spherical coverage‚Äîspecifically in traditionally under-sampled regions‚Äîis a critical factor for robust 3DGS reconstruction.
      </p>

      <!-- Table 3 -->
      <div class="table-container">
        <table>
          <caption>Table 3. Ablation on <strong>Coinbank</strong>: PSNR trends vs. Coverage %.</caption>
          <thead>
            <tr>
              <th>Coverage</th>
              <th style="color:#666;">Test 7k</th>
              <th style="color:#666;">Test 30k</th>
              <th style="color:#666;">Train 7k</th>
              <th style="color:#666;">Train 30k</th>
              <th style="background:#eefcf1; border-bottom:2px solid #bceacb;">Final 7k</th>
              <th style="background:#eefcf1; border-bottom:2px solid #bceacb;">Final 30k</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>100%</td><td>26.00</td><td>27.31</td><td>29.01</td><td>31.45</td><td style="font-weight:700;">26.39</td><td style="font-weight:700;">27.84</td></tr>
            <tr><td>90%</td><td>25.78</td><td>26.77</td><td>29.01</td><td>31.05</td><td>26.20</td><td>27.32</td></tr>
            <tr><td>80%</td><td>25.54</td><td>26.48</td><td>28.65</td><td>31.42</td><td>25.94</td><td>27.12</td></tr>
            <tr><td>70%</td><td>25.38</td><td>26.20</td><td>29.19</td><td>31.67</td><td>25.87</td><td>26.90</td></tr>
            <tr><td>60%</td><td>25.05</td><td>25.48</td><td>29.48</td><td>32.34</td><td>25.61</td><td>26.36</td></tr>
            <tr><td>50%</td><td>24.52</td><td>24.85</td><td>29.54</td><td>33.24</td><td>25.17</td><td>25.93</td></tr>
            <tr><td>40%</td><td>23.43</td><td>23.58</td><td>30.53</td><td>34.47</td><td>24.34</td><td>24.98</td></tr>
          </tbody>
        </table>
      </div>

      <!-- Table 4 -->
      <div class="table-container">
        <table>
          <caption>Table 4. Ablation on <strong>Miniclawmachine</strong>: PSNR trends vs. Coverage %.</caption>
          <thead>
            <tr>
              <th>Coverage</th>
              <th style="color:#666;">Test 7k</th>
              <th style="color:#666;">Test 30k</th>
              <th style="color:#666;">Train 7k</th>
              <th style="color:#666;">Train 30k</th>
              <th style="background:#eefcf1; border-bottom:2px solid #bceacb;">Final 7k</th>
              <th style="background:#eefcf1; border-bottom:2px solid #bceacb;">Final 30k</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>100%</td><td>24.71</td><td>26.22</td><td>25.94</td><td>29.16</td><td style="font-weight:700;">24.87</td><td style="font-weight:700;">26.60</td></tr>
            <tr><td>90%</td><td>24.20</td><td>25.33</td><td>25.68</td><td>28.53</td><td>24.39</td><td>25.74</td></tr>
            <tr><td>80%</td><td>23.98</td><td>24.87</td><td>26.15</td><td>28.95</td><td>24.25</td><td>25.39</td></tr>
            <tr><td>70%</td><td>24.17</td><td>25.01</td><td>26.44</td><td>29.99</td><td>24.46</td><td>25.65</td></tr>
            <tr><td>60%</td><td>23.67</td><td>24.27</td><td>26.66</td><td>30.37</td><td>24.05</td><td>25.05</td></tr>
            <tr><td>50%</td><td>20.01</td><td>19.93</td><td>30.75</td><td>34.58</td><td>21.39</td><td>21.81</td></tr>
            <tr><td>40%</td><td>21.35</td><td>21.25</td><td>28.48</td><td>32.77</td><td>22.26</td><td>22.72</td></tr>
          </tbody>
        </table>
        <p style="font-size:13px; color:#777; margin-top:8px; text-align:center;">
          * Note: For brevity, intermediate 5% intervals are omitted from the web view but are available in the full dataset download.
        </p>
      </div>
    </section>

    <!-- Downloads & Ack -->
    <section class="card">
      <div class="hrow"><span class="hicon">‚¨áÔ∏è</span><h2>Resources</h2></div>
      <ul>
        <li>
          <strong>APK Release (v1.1):</strong> 
          <a href="https://github.com/zyz-nwpu/An-Object-Centered-Data-Acquisition-Method-for-3D-Gaussian-Splatting-using-Mobile-Phone/releases/tag/v1.1">Download App & Assets</a>
          <br><span style="color:#666; font-size:13px;">Includes `camera-6-core-debug.apk` (Full feature) and experimental builds.</span>
        </li>
      </ul>
      
      <div class="hrow" style="margin-top:24px;"><span class="hicon">ü§ù</span><h2>Acknowledgements</h2></div>
      <p>
        This project builds upon <a href="https://github.com/graphdeco-inria/gaussian-splatting" target="_blank">3D Gaussian Splatting</a> and the <a href="https://github.com/FossifyOrg/Camera" target="_blank">Fossify Camera</a> open-source project.
      </p>
    </section>
    
    <footer>
      &copy; 2025 Yuezhe Zhang. <br>
      Northwestern Polytechnical University (NWPU)
    </footer>
  </main>
</body>
</html>

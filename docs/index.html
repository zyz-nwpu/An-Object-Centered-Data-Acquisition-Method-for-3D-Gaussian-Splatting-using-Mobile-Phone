<!doctype html>
<html lang="en" style="--lh:2.0;">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>3DGS Object-Centered Capture â€” Demo & Overview</title>
  <meta name="description" content="Concise overview and a single demo for a mobile, object-centered capture workflow for 3D Gaussian Splatting (3DGS)." />
  <link rel="canonical" href="https://zyz-nwpu.github.io/An-Object-Centered-Data-Acquisition-Method-for-3D-Gaussian-Splatting-using-Mobile-Phone/" />
  <style>
    :root{
      --fg:#111; --muted:#666; --line:#eaeaea; --bg:#f7f7f7; --card:#fff;
      --radius:14px; --pad:16px; --maxw:1100px;
      --vid-h: 360px;  /* default equal height for both videos */
    }
    *{box-sizing:border-box}
    body{
      margin:0;
      font-family:system-ui,-apple-system,"Segoe UI",Roboto,Arial,sans-serif;
      color:var(--fg); background:var(--bg);
      line-height:var(--lh);
      font-size:15px;
    }
    a{color:#0b57d0;text-decoration:none}
    nav{position:sticky;top:0;z-index:10;background:#fff;border-bottom:1px solid var(--line)}
    .navwrap{max-width:var(--maxw);margin:0 auto;padding:10px var(--pad);display:flex;gap:10px;flex-wrap:wrap;align-items:center;justify-content:space-between}
    .btn{display:inline-block;padding:7px 12px;border:1px solid var(--line);border-radius:10px;background:#fff;color:var(--fg)}
    .btn:hover{background:#fafafa}
    .wrap{max-width:var(--maxw);margin:18px auto 26px;padding:0 var(--pad)}
    .card{background:var(--card);border:1px solid var(--line);border-radius:var(--radius);padding:16px;box-shadow:0 3px 12px rgba(0,0,0,.04);margin-bottom:14px}

    /* Larger title */
    h1{margin:0 0 8px;font-size:30px;line-height:1.25}

    .hrow{display:flex;align-items:center;gap:8px;margin:8px 0}
    .hicon{width:22px;display:inline-flex;justify-content:center}

    /* Section headings enlarged (applies to Demo & Figure, etc.) */
    .htxt{font-size:20px;font-weight:600;line-height:1.4}

    p{margin:8px 0}
    ul{margin:8px 0 0 20px}
    li{margin:6px 0}
    .hr{height:1px;background:var(--line);margin:10px 0}
    .muted{color:var(--muted);font-size:13px}
    footer{margin:20px 0;color:var(--muted);font-size:13px;text-align:center}

    /* Media blocks */
    figure{margin:0;background:#fff;border:1px solid var(--line);border-radius:12px;overflow:hidden}
    .media-block{padding:12px}
    .media-block img,
    .media-block video{
      display:block;
      border-radius:8px;
      background:#fff;
    }

    /* We place descriptions ABOVE media */
    figcaption{display:none}
    .media-desc{
      margin: 0 0 10px 0;
      padding: 10px 12px;
      background:#fff;
      border:1px solid var(--line);
      border-radius:10px;
      font-size:14px;
      color:#333;
    }

    /* A) Image width-based scaling (as before) */
    .is-figure .media-block img{
      width: var(--fig-w, 100%);   /* e.g., 760px or 80% */
      max-width: 100%;
      height: auto;
    }

    /* === Two videos side-by-side === */
    .videos-intro{ margin:12px 0; }
    .video-grid{
      display:grid;
      grid-template-columns: 1fr 1fr;
      gap:16px;
      padding:4px; /* visual spacing inside the card */
    }
    @media (max-width: 900px){
      .video-grid{ grid-template-columns: 1fr; }
    }

    .video-cell{
      border:1px solid var(--line);
      border-radius:12px;
      padding:12px;
      background:#fff;
      display:flex;
      flex-direction:column;
      gap:10px;
    }
    .video-title{
      font-size:16px;
      font-weight:600;
      line-height:1.3;
    }
    .video-frame{
      display:flex;
      align-items:center;
      justify-content:center;
      border-radius:10px;
      overflow:hidden;
      background:#fff;
      height: var(--vid-h);   /* equal height for both videos */
    }
    .video-frame > video{
      height:100%;
      width:auto;
      max-width:100%;
      object-fit: contain;    /* change to 'cover' to fill with cropping */
      display:block;
    }
  </style>
</head>
<body>

  <!-- Top nav -->
  <nav>
    <div class="navwrap">
      <div style="display:flex;gap:8px;flex-wrap:wrap">
        <a class="btn" href="https://github.com/zyz-nwpu/An-Object-Centered-Data-Acquisition-Method-for-3D-Gaussian-Splatting-using-Mobile-Phone">View Code</a>
        <a class="btn" href="https://github.com/zyz-nwpu/An-Object-Centered-Data-Acquisition-Method-for-3D-Gaussian-Splatting-using-Mobile-Phone/releases/tag/v1">Release v1</a>
      </div>
      <div class="muted">Overview & demo</div>
    </div>
  </nav>

  <main class="wrap">

    <!-- Title + overview -->
    <section class="card">
      <h1>An Object-Centered Data Acquisition Method for 3D Gaussian Splatting using Mobile Phone</h1>
      <div class="hr"></div>

      <div class="hrow"><span class="hicon">ðŸ”Ž</span><div class="htxt">Overview</div></div>
      <p>
        A mobile, <strong>object-centered</strong> capture workflow for <strong>3D Gaussian Splatting (3DGS)</strong>.
        After a one-time calibration, device orientations align to a baseline; the camera forward vector is indexed on a
        <strong>discretized spherical grid</strong>. <strong>Area-weighted</strong> coverage guides motion in real time
        to avoid polar bias, and a <strong>stability gate</strong> from smoothed IMU signals admits only steady frames.
        Images and poses are used for off-device 3DGS reconstruction.
      </p>

      <div class="hrow"><span class="hicon">ðŸ§­</span><div class="htxt">Key Contributions</div></div>
      <ul>
        <li>IMU-based orientations mapped to an <strong>object-centered spherical</strong> coordinate system.</li>
        <li><strong>Real-time, area-weighted coverage</strong> feedback for uniform and complete viewpoints.</li>
        <li><strong>Dual-signal stability gate</strong> (linear acceleration + angular velocity, smoothed).</li>
      </ul>

      <div class="hrow"><span class="hicon">ðŸ§©</span><div class="htxt">System Outline</div></div>
      <ul>
        <li><strong>Calibration:</strong> record a baseline orientation; later poses are referenced relatively.</li>
        <li><strong>Pose sensing:</strong> log quaternion orientation, linear acceleration, and angular velocity.</li>
        <li><strong>Stability gating:</strong> exponential averages vs. thresholds over a holding window; discard unsteady frames.</li>
        <li><strong>Spherical mapping:</strong> project the optical axis to lonâ€“lat; quantize to grid indices and update online.</li>
        <li><strong>Area-weighted coverage:</strong> accumulate by spherical surface area; light morphological refinements.</li>
      </ul>

      <div class="hrow"><span class="hicon">ðŸ§ª</span><div class="htxt">Experimental Setting</div></div>
      <ul>
        <li><strong>Device:</strong> Redmi K70 Pro (angle logging & stability gating)</li>
        <li><strong>Reconstruction:</strong> 3DGS on NVIDIA RTX 5090D</li>
        <li><strong>Evaluation:</strong> tabletop objects for analysis and visualization</li>
      </ul>
    </section>

    <!-- Demo & Figure -->
    <section class="card">
      <div class="hrow"><span class="hicon">ðŸŽ¬</span><div class="htxt">Demo & Figure</div></div>

      <!-- 1) Method figure (first item) -->
      <figure class="is-figure" style="--fig-w: 760px;">
        <!-- Description ABOVE the image -->
        <div class="media-desc">
          <strong>Method figure.</strong> A compact summary of our <em>object-centered</em> mobile capture loop:
          a one-time calibration, real-time indexing of the camera forward vector on a <em>discretized spherical grid</em>,
          <em>area-weighted</em> coverage feedback to guide motion uniformly, and a <em>stability gate</em> that filters
          shaky frames via smoothed IMU signals. This mirrors the method section in the PDF and clarifies the inputs and
          closed-loop feedback used for 3DGS reconstruction.
        </div>
        <div class="media-block">
          <img src="./ç»˜å›¾1_01.png" alt="Method figure (display-only)" loading="lazy">
        </div>
      </figure>

      <!-- 2) Paired videos (side-by-side) -->
      <div class="videos-intro media-desc">
        <strong>Two videos:</strong> the left video records the <em>capture process</em> with real-time coverage and stability indicators;
        the right video shows the <em>reconstruction result</em> rendered from the collected images and poses.
      </div>

      <div class="video-grid">
        <!-- Left: Capture process -->
        <div class="video-cell">
          <div class="video-title">Capture Process (screen recording)</div>
          <div class="video-frame">
            <video controls autoplay muted loop playsinline preload="metadata"
              src="https://github.com/zyz-nwpu/An-Object-Centered-Data-Acquisition-Method-for-3D-Gaussian-Splatting-using-Mobile-Phone/releases/download/v1/capturing.mp4">
            </video>
          </div>
        </div>

        <!-- Right: Reconstruction result -->
        <div class="video-cell">
          <div class="video-title">Reconstruction Result (3DGS)</div>
          <div class="video-frame">
            <video controls autoplay muted loop playsinline preload="metadata"
              src="https://github.com/zyz-nwpu/An-Object-Centered-Data-Acquisition-Method-for-3D-Gaussian-Splatting-using-Mobile-Phone/releases/download/v1/recon.mp4">
            </video>
          </div>
        </div>
      </div>
    </section>

    <!-- Downloads -->
    <section class="card">
      <div class="hrow"><span class="hicon">ðŸ“¦</span><div class="htxt">Downloads</div></div>
      <ul>
        <li><a href="https://github.com/zyz-nwpu/An-Object-Centered-Data-Acquisition-Method-for-3D-Gaussian-Splatting-using-Mobile-Phone/releases/tag/v1">All assets in Release v1</a></li>
      </ul>
    </section>

    <footer>Â© 2025 zyz-nwpu</footer>
  </main>

</body>
</html>
